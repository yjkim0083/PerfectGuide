{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1 Accuracy(정확도)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class MyDummyClassifier(BaseEstimator):\n",
    "    # fit() 메소드는 아무것도 학습하지 않음\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    \n",
    "    # predict() 메소드는 단순히 성별 feature가 1이면 0, 0 이면 1로 예측\n",
    "    def predict(self, X):\n",
    "        pred = np.zeros( (X.shape[0], 1))\n",
    "        for i in range(X.shape[0]):\n",
    "            if X['Sex'].iloc[i] == 1:\n",
    "                pred[i] = 0\n",
    "            else:\n",
    "                pred[i] = 1\n",
    "                \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# null 처리 함수\n",
    "def fillna(df):\n",
    "    df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
    "    df['Cabin'].fillna('N', inplace=True)\n",
    "    df['Embarked'].fillna('N', inplace=True)\n",
    "    df['Fare'].fillna(0, inplace=True)\n",
    "    return df\n",
    "\n",
    "# 머신러닝 알고리즘에 불필요한 속성 제거\n",
    "def drop_features(df):\n",
    "    df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "# 레이블 인코딩 수행\n",
    "def format_features(df):\n",
    "    df['Cabin'] = df['Cabin'].str[:1]\n",
    "    features = ['Cabin','Sex','Embarked']\n",
    "    \n",
    "    for feature in features:\n",
    "        le = LabelEncoder()\n",
    "        le = le.fit(df[feature])\n",
    "        df[feature] = le.transform(df[feature])\n",
    "    return df\n",
    "\n",
    "# 앞에서 설정한 Data Preprocessing 함수 호출\n",
    "def transform_features(df):\n",
    "    df = fillna(df)\n",
    "    df = drop_features(df)\n",
    "    df = format_features(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Classifier의 정확도는: 0.7877\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 원본 데이터를 재로딩, 데이터 가공, 학습데이터/테스트 데이터 분할\n",
    "t_df = pd.read_csv(\"./titanic_train.csv\")\n",
    "y_t_df = t_df['Survived']\n",
    "X_t_df = t_df.drop('Survived', axis=1)\n",
    "X_t_df = transform_features(X_t_df)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_t_df, y_t_df, \n",
    "                                                    test_size=0.2, random_state=0)\n",
    "\n",
    "# 위에서 생성한 Dummy Classifier를 이용하여 학습/예측/평가 수행\n",
    "myclf = MyDummyClassifier()\n",
    "myclf.fit(X_train, y_train)\n",
    "\n",
    "mypredictions = myclf.predict(X_test)\n",
    "print(\"Dummy Classifier의 정확도는: {:.4f}\".format(accuracy_score(y_test, mypredictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  5. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ... 10.  0.  0.]\n",
      " [ 0.  0.  0. ... 16.  9.  0.]\n",
      " ...\n",
      " [ 0.  0.  1. ...  6.  0.  0.]\n",
      " [ 0.  0.  2. ... 12.  0.  0.]\n",
      " [ 0.  0. 10. ... 12.  1.  0.]]\n",
      "### digits.data.shape: (1797, 64)\n",
      "[0 1 2 ... 8 9 8]\n",
      "### digits.target.shape: (1797,)\n"
     ]
    }
   ],
   "source": [
    "# mnist dataset\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class MyFakeClassifier(BaseEstimator):\n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "    \n",
    "    # 입력값으로 들어오는 X데이터 셋의 크기만큼 모두 0값으로 만들어서 반환\n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X), 1), dtype=bool)\n",
    "    \n",
    "# 사이킷런의 내장 데이터 셋인 load_digits()를 활용하여 MNIST 데이터 로딩\n",
    "digits = load_digits()\n",
    "\n",
    "print(digits.data)\n",
    "print(\"### digits.data.shape:\", digits.data.shape)\n",
    "print(digits.target)\n",
    "print(\"### digits.target.shape:\", digits.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# digits 번호가 7번이면 True이고, 이를 astype(int)로 1로 변환, 7번이 아니면 False이고 0으로 반환\n",
    "y = (digits.target == 7).astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, y, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "레이블 테스트 세트 크기: (450,)\n",
      "테스트 세트 레이블 0과 1의 분포도\n",
      "0    405\n",
      "1     45\n",
      "dtype: int64\n",
      "모든 예측을 0으로 하여도 정확도는:0.900\n"
     ]
    }
   ],
   "source": [
    "# 불균형한 레이블 데이터 분포도 확인.\n",
    "print(\"레이블 테스트 세트 크기:\", y_test.shape)\n",
    "print(\"테스트 세트 레이블 0과 1의 분포도\")\n",
    "print(pd.Series(y_test).value_counts())\n",
    "\n",
    "# Fake Classifier로 학습/예측/평가\n",
    "fakeclf = MyFakeClassifier()\n",
    "fakeclf.fit(X_train, y_train)\n",
    "fakepred = fakeclf.predict(X_test)\n",
    "print(\"모든 예측을 0으로 하여도 정확도는:{:.3f}\".format(accuracy_score(y_test, fakepred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[405,   0],\n",
       "       [ 45,   0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, fakepred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정밀도(Precision)과 재현율(Recall)\n",
    "\n",
    "- 정밀도 = TP / (FP + TP)\n",
    "  - 정밀도는 예측을 Positive로 한 대상 중에 예측과 실제 값이 Positive로 일치한 데이터의 비율을 뜻함\n",
    "- 재현율 = TP / (FN + TP)\n",
    "  - 재현율은 실제 값이 Positive인 대상 중에 예측과 실제 값이 Positive로 일치한 데이터의 비율을 뜻함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MyFakeClassifier의 예측 결과로 정밀도와 재현율 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정밀도(Precision): 0.0\n",
      "재현율(Recall): 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yjkim/miniconda3/envs/ai/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "print(\"정밀도(Precision):\", precision_score(y_test, fakepred))\n",
    "print(\"재현율(Recall):\", recall_score(y_test, fakepred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 오차행렬, 정확도, 정밀도, 재현율을 한꺼번에 계산하는 함수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "def get_clf_eval(y_test, pred):\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    print(\"오차 행렬\")\n",
    "    print(confusion)\n",
    "    print(\"정확도:{0:.4f}, 정밀도:{1:.4f}, 재현율:{2:.4f}\".format(accuracy, precision, recall))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[104  14]\n",
      " [ 13  48]]\n",
      "정확도:0.8492, 정밀도:0.7742, 재현율:0.7869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yjkim/miniconda3/envs/ai/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "t_df = pd.read_csv(\"./titanic_train.csv\")\n",
    "y_t_df = t_df['Survived']\n",
    "X_t_df = t_df.drop('Survived', axis=1)\n",
    "X_t_df = transform_features(X_t_df)\n",
    "\n",
    "x_t, x_te, y_t, y_te = train_test_split(X_t_df, y_t_df, test_size=0.2, random_state=11)\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "\n",
    "lr_clf.fit(x_t, y_t)\n",
    "pred = lr_clf.predict(x_te)\n",
    "\n",
    "get_clf_eval(y_te, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision/Recall Trade-off\n",
    "\n",
    "#### predict_proba() 메소드 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_proba()결과 Shape: (179, 2)\n",
      "pred_proba array에서 앞 3개만 샘플로 추출 \n",
      ": [[0.46184106 0.53815894]\n",
      " [0.87866995 0.12133005]\n",
      " [0.8771695  0.1228305 ]]\n"
     ]
    }
   ],
   "source": [
    "pred_proba = lr_clf.predict_proba(x_te)\n",
    "pred = lr_clf.predict(x_te)\n",
    "print(\"pred_proba()결과 Shape: {}\".format(pred_proba.shape))\n",
    "print(\"pred_proba array에서 앞 3개만 샘플로 추출 \\n:\", pred_proba[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "두개의 class 중에서 더 큰 확률을 클래스 값으로 예측 \n",
      " [[0.46184106 0.53815894 1.        ]\n",
      " [0.87866995 0.12133005 0.        ]\n",
      " [0.8771695  0.1228305  0.        ]\n",
      " [0.88265546 0.11734454 0.        ]\n",
      " [0.8551068  0.1448932  0.        ]\n",
      " [0.88225581 0.11774419 0.        ]\n",
      " [0.88842064 0.11157936 0.        ]\n",
      " [0.20876242 0.79123758 1.        ]\n",
      " [0.78270934 0.21729066 0.        ]\n",
      " [0.3695523  0.6304477  1.        ]\n",
      " [0.89982999 0.10017001 0.        ]\n",
      " [0.87492225 0.12507775 0.        ]\n",
      " [0.87716351 0.12283649 0.        ]\n",
      " [0.88837465 0.11162535 0.        ]\n",
      " [0.43645496 0.56354504 1.        ]\n",
      " [0.85895814 0.14104186 0.        ]\n",
      " [0.90368543 0.09631457 0.        ]\n",
      " [0.7333317  0.2666683  0.        ]\n",
      " [0.72463445 0.27536555 0.        ]\n",
      " [0.17180573 0.82819427 1.        ]\n",
      " [0.75352758 0.24647242 0.        ]\n",
      " [0.61909451 0.38090549 0.        ]\n",
      " [0.85459198 0.14540802 0.        ]\n",
      " [0.81472367 0.18527633 0.        ]\n",
      " [0.88800331 0.11199669 0.        ]\n",
      " [0.76544616 0.23455384 0.        ]\n",
      " [0.85967062 0.14032938 0.        ]\n",
      " [0.92588516 0.07411484 0.        ]\n",
      " [0.71949207 0.28050793 0.        ]\n",
      " [0.6953415  0.3046585  0.        ]\n",
      " [0.05271904 0.94728096 1.        ]\n",
      " [0.18267874 0.81732126 1.        ]\n",
      " [0.87307269 0.12692731 0.        ]\n",
      " [0.17389997 0.82610003 1.        ]\n",
      " [0.60040646 0.39959354 0.        ]\n",
      " [0.76544616 0.23455384 0.        ]\n",
      " [0.92761436 0.07238564 0.        ]\n",
      " [0.38882877 0.61117123 1.        ]\n",
      " [0.94702506 0.05297494 0.        ]\n",
      " [0.89608724 0.10391276 0.        ]\n",
      " [0.64911585 0.35088415 0.        ]\n",
      " [0.91667322 0.08332678 0.        ]\n",
      " [0.17823178 0.82176822 1.        ]\n",
      " [0.29209791 0.70790209 1.        ]\n",
      " [0.36957839 0.63042161 1.        ]\n",
      " [0.36956207 0.63043793 1.        ]\n",
      " [0.08117422 0.91882578 1.        ]\n",
      " [0.64179125 0.35820875 0.        ]\n",
      " [0.05108121 0.94891879 1.        ]\n",
      " [0.88796871 0.11203129 0.        ]\n",
      " [0.40707407 0.59292593 1.        ]\n",
      " [0.88837465 0.11162535 0.        ]\n",
      " [0.86719201 0.13280799 0.        ]\n",
      " [0.27451017 0.72548983 1.        ]\n",
      " [0.69054006 0.30945994 0.        ]\n",
      " [0.80315851 0.19684149 0.        ]\n",
      " [0.77372783 0.22627217 0.        ]\n",
      " [0.87716846 0.12283154 0.        ]\n",
      " [0.84576224 0.15423776 0.        ]\n",
      " [0.56748703 0.43251297 0.        ]\n",
      " [0.71978448 0.28021552 0.        ]\n",
      " [0.89918754 0.10081246 0.        ]\n",
      " [0.45440757 0.54559243 1.        ]\n",
      " [0.48581316 0.51418684 1.        ]\n",
      " [0.55571886 0.44428114 0.        ]\n",
      " [0.90541086 0.09458914 0.        ]\n",
      " [0.3332117  0.6667883  1.        ]\n",
      " [0.40593389 0.59406611 1.        ]\n",
      " [0.04817486 0.95182514 1.        ]\n",
      " [0.85184163 0.14815837 0.        ]\n",
      " [0.8710249  0.1289751  0.        ]\n",
      " [0.83150613 0.16849387 0.        ]\n",
      " [0.896085   0.103915   0.        ]\n",
      " [0.05198659 0.94801341 1.        ]\n",
      " [0.80133554 0.19866446 0.        ]\n",
      " [0.88837465 0.11162535 0.        ]\n",
      " [0.65160708 0.34839292 0.        ]\n",
      " [0.81631824 0.18368176 0.        ]\n",
      " [0.16434645 0.83565355 1.        ]\n",
      " [0.87716846 0.12283154 0.        ]\n",
      " [0.20517628 0.79482372 1.        ]\n",
      " [0.35491385 0.64508615 1.        ]\n",
      " [0.06893077 0.93106923 1.        ]\n",
      " [0.86680074 0.13319926 0.        ]\n",
      " [0.05103073 0.94896927 1.        ]\n",
      " [0.04957798 0.95042202 1.        ]\n",
      " [0.84649357 0.15350643 0.        ]\n",
      " [0.87452109 0.12547891 0.        ]\n",
      " [0.12558587 0.87441413 1.        ]\n",
      " [0.88837465 0.11162535 0.        ]\n",
      " [0.88837465 0.11162535 0.        ]\n",
      " [0.76544616 0.23455384 0.        ]\n",
      " [0.7677492  0.2322508  0.        ]\n",
      " [0.88837465 0.11162535 0.        ]\n",
      " [0.36956207 0.63043793 1.        ]\n",
      " [0.9243003  0.0756997  0.        ]\n",
      " [0.07113905 0.92886095 1.        ]\n",
      " [0.89928964 0.10071036 0.        ]\n",
      " [0.49449289 0.50550711 1.        ]\n",
      " [0.03489847 0.96510153 1.        ]\n",
      " [0.4983366  0.5016634  1.        ]\n",
      " [0.90529741 0.09470259 0.        ]\n",
      " [0.05203462 0.94796538 1.        ]\n",
      " [0.90246536 0.09753464 0.        ]\n",
      " [0.47004968 0.52995032 1.        ]\n",
      " [0.87160978 0.12839022 0.        ]\n",
      " [0.85891102 0.14108898 0.        ]\n",
      " [0.85184194 0.14815806 0.        ]\n",
      " [0.55028865 0.44971135 0.        ]\n",
      " [0.89217132 0.10782868 0.        ]\n",
      " [0.88297657 0.11702343 0.        ]\n",
      " [0.89111059 0.10888941 0.        ]\n",
      " [0.59652399 0.40347601 0.        ]\n",
      " [0.34592268 0.65407732 1.        ]\n",
      " [0.88800331 0.11199669 0.        ]\n",
      " [0.92891136 0.07108864 0.        ]\n",
      " [0.87564878 0.12435122 0.        ]\n",
      " [0.80156617 0.19843383 0.        ]\n",
      " [0.07408546 0.92591454 1.        ]\n",
      " [0.93135644 0.06864356 0.        ]\n",
      " [0.88838352 0.11161648 0.        ]\n",
      " [0.86916314 0.13083686 0.        ]\n",
      " [0.93636007 0.06363993 0.        ]\n",
      " [0.67859297 0.32140703 0.        ]\n",
      " [0.98834959 0.01165041 0.        ]\n",
      " [0.88838352 0.11161648 0.        ]\n",
      " [0.88374898 0.11625102 0.        ]\n",
      " [0.68323753 0.31676247 0.        ]\n",
      " [0.322407   0.677593   1.        ]\n",
      " [0.67845123 0.32154877 0.        ]\n",
      " [0.03489847 0.96510153 1.        ]\n",
      " [0.54609316 0.45390684 0.        ]\n",
      " [0.26455364 0.73544636 1.        ]\n",
      " [0.5580569  0.4419431  0.        ]\n",
      " [0.430024   0.569976   1.        ]\n",
      " [0.64977195 0.35022805 0.        ]\n",
      " [0.25169524 0.74830476 1.        ]\n",
      " [0.81387371 0.18612629 0.        ]\n",
      " [0.8960598  0.1039402  0.        ]\n",
      " [0.19663891 0.80336109 1.        ]\n",
      " [0.09108519 0.90891481 1.        ]\n",
      " [0.85184194 0.14815806 0.        ]\n",
      " [0.88196673 0.11803327 0.        ]\n",
      " [0.89867002 0.10132998 0.        ]\n",
      " [0.90837824 0.09162176 0.        ]\n",
      " [0.3322366  0.6677634  1.        ]\n",
      " [0.92434542 0.07565458 0.        ]\n",
      " [0.76623263 0.23376737 0.        ]\n",
      " [0.08182136 0.91817864 1.        ]\n",
      " [0.83171698 0.16828302 0.        ]\n",
      " [0.57117216 0.42882784 0.        ]\n",
      " [0.36883024 0.63116976 1.        ]\n",
      " [0.3632386  0.6367614  1.        ]\n",
      " [0.87722414 0.12277586 0.        ]\n",
      " [0.22213284 0.77786716 1.        ]\n",
      " [0.11906021 0.88093979 1.        ]\n",
      " [0.51232675 0.48767325 0.        ]\n",
      " [0.86702834 0.13297166 0.        ]\n",
      " [0.24829921 0.75170079 1.        ]\n",
      " [0.30955208 0.69044792 1.        ]\n",
      " [0.85019395 0.14980605 0.        ]\n",
      " [0.20722483 0.79277517 1.        ]\n",
      " [0.90873926 0.09126074 0.        ]\n",
      " [0.33327933 0.66672067 1.        ]\n",
      " [0.61957608 0.38042392 0.        ]\n",
      " [0.34872038 0.65127962 1.        ]\n",
      " [0.11589419 0.88410581 1.        ]\n",
      " [0.69084857 0.30915143 0.        ]\n",
      " [0.90835893 0.09164107 0.        ]\n",
      " [0.10689976 0.89310024 1.        ]\n",
      " [0.88842064 0.11157936 0.        ]\n",
      " [0.14561737 0.85438263 1.        ]\n",
      " [0.74917623 0.25082377 0.        ]\n",
      " [0.7596266  0.2403734  0.        ]\n",
      " [0.59996987 0.40003013 0.        ]\n",
      " [0.93771227 0.06228773 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# 예측 확률 array와 예측 결과값 array를 concatenate 하여 예측 확률과 결과값을 한눈에 확인\n",
    "pred_proba_result = np.concatenate([pred_proba, pred.reshape(-1, 1)], axis=1)\n",
    "print(\"두개의 class 중에서 더 큰 확률을 클래스 값으로 예측 \\n\", pred_proba_result[:-3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binarizer 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "X = [\n",
    "    [1, -1, 2],\n",
    "    [2, 0, 0],\n",
    "    [0, 1.1, 1.2]\n",
    "]\n",
    "\n",
    "# threshold 기준값보다 같거나 작으면 0을, 크면 1을 반환\n",
    "binarizer = Binarizer(threshold=1.1)\n",
    "print(binarizer.fit_transform(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 분류 결정 임계값 0.5 기반에서 Binarizer를 이용하여 예측값 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[104  14]\n",
      " [ 13  48]]\n",
      "정확도:0.8492, 정밀도:0.7742, 재현율:0.7869\n"
     ]
    }
   ],
   "source": [
    "# Binarizer의 threshold 설정값, 분류 결정 임계값임\n",
    "custom_threshold = 0.5\n",
    "\n",
    "# predict_proba() 반환값의 두번째 컬럼, 즉 Positive 클래스 컬럼 하나만 추출 하여 Binarizer를 적용\n",
    "pred_proba_1 = pred_proba[:, 1].reshape(-1, 1)\n",
    "\n",
    "binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_1)\n",
    "custom_predict = binarizer.transform(pred_proba_1)\n",
    "\n",
    "get_clf_eval(y_te, custom_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ai] *",
   "language": "python",
   "name": "conda-env-ai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
